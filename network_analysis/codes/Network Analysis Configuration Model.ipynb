{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "middle-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import math\n",
    "import collections\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "canadian-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/info_cm.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-conspiracy",
   "metadata": {},
   "source": [
    "# Configuration Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_adjlist(\"../data/CM.adjlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15690 6955000\n",
      "0.0565078681823775\n"
     ]
    }
   ],
   "source": [
    "N = len(G.nodes)\n",
    "L = len(G.edges)\n",
    "density = nx.density(G)\n",
    "print(N,L)\n",
    "print(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optimum-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['name'] = 'Real world'\n",
    "data['N_nodes'] = N\n",
    "data['N_edges'] = L\n",
    "data['density'] = density\n",
    "with open(filename,'w') as jf:\n",
    "    json.dump(data,jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-louis",
   "metadata": {},
   "source": [
    "## Degree distribution analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excess-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [(n,d) for n, d in G.degree()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respected-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,'r') as jf:\n",
    "    data = json.load(jf)\n",
    "\n",
    "data['degrees'] = degrees\n",
    "\n",
    "with open(filename,'w') as jf:\n",
    "    json.dump(data,jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-freight",
   "metadata": {},
   "source": [
    "## Connected components analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "improving-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average componets size:  3922.5\n",
      "[15684, 2, 2, 2] etc...\n"
     ]
    }
   ],
   "source": [
    "components =  [c for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "avg_size = np.average([len(c) for c in components])\n",
    "print('average componets size: ', avg_size)\n",
    "print([len(c) for c in components[:7]],'etc...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sacred-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,'r') as jf:\n",
    "    data = json.load(jf)\n",
    "\n",
    "data['components'] = [len(c) for c in components]\n",
    "\n",
    "with open(filename,'w') as jf:\n",
    "    json.dump(data,jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baking-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = G.subgraph(components[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-director",
   "metadata": {},
   "source": [
    "## Path analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_shortest_path = nx.average_shortest_path_length(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,'r') as jf:\n",
    "    data = json.load(jf)\n",
    "\n",
    "data['avg_shortest_path'] = avg_shortest_path\n",
    "\n",
    "with open(filename,'w') as jf:\n",
    "    json.dump(data,jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-tutorial",
   "metadata": {},
   "source": [
    "## Clustering Coefficient, Density analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterings = [(n,d) for n,d in nx.clustering(G)]\n",
    "\n",
    "with open(filename,'r') as jf:\n",
    "    data = json.load(jf)\n",
    "\n",
    "data['clusterings'] =clusterings \n",
    "\n",
    "with open(filename,'w') as jf:\n",
    "    json.dump(data,jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-correlation",
   "metadata": {},
   "source": [
    "## Centrality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,'r') as jf:\n",
    "    data = json.load(jf)\n",
    "\n",
    "data['degree_centrality'] = degree_centrality \n",
    "\n",
    "with open(filename,'w') as jf:\n",
    "    json.dump(data,jf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
